% ------------------
% -- Assignment 1 --
% -- Math 4171 -----

\documentclass[11pt,oneside]{article}

%\usepackage{subfigure}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{adjustbox}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage{mathrsfs}
\usepackage[driver=pdftex]{geometry}
\usepackage{import}
%\usepackage{titleformat{\section
%        {\normalfont\normalzie\bfseries}{Helo.}{1em}{}


\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
 
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{proof}{Proof}
 
\lstset{style=mystyle}

%\usepackage[margin=0.5in]{geometry}
\usepackage{inputenc}

\newcommand{\Real}{\mathbb{R}}
\newcommand{\Int}{\mathbb{Z}}
\newcommand{\Nat}{\mathbb{N}}
\newcommand{\Complex}{\mathbb{C}}
\newcommand{\vect}[1]{\boldsymbol{#1}}

\renewcommand{\Re}[1]{\mathfrak{Re}\left\lbrace{#1}\right\rbrace}
\renewcommand{\Im}[1]{\mathfrak{Im}\left\lbrace{#1}\right\rbrace}

\title{{\bf MATH 3172 3.0\\ Combinatorial Optimization}\\\vspace{10pt} \large Midterm I     
    \author{Jacques Nel}
}

\begin{document}

\maketitle

\section{Hill climb}

\subsection{Our implementation}

Our naive implementation of the hill climbing algorithm is found in
\texttt{hill\_climb.py} in the function \texttt{hill\_climb()}.

\subsection{\texttt{grid1} and \texttt{grid2}}

$$
\mathtt{grid1}=
\begin{bmatrix}
    3 & 7 & 2 & 8 \\
    5 & 2 & 9 & 1 \\
    5 & 3 & 3 & 1 \\
\end{bmatrix},
\quad\quad\text{and}\quad\quad
\mathtt{grid2}=
\begin{bmatrix}
    0 & 0 & 0 & 1 & 1 \\
    0 & 0 & 2 & 8 & 10 \\
    0 & 2 & 4 & 8 & 16 \\
    1 & 4 & 8 & 16 & 32 \\
\end{bmatrix}.
$$

Code which sets up and calls \texttt{hill\_climb()} for \texttt{grid1},
\texttt{grid2}, and \texttt{grid3} is found in the same file. The global maximum of \texttt{grid1} and \texttt{grid2} was trivial to find using
a naive implementation of the hill-climb. Both adjacent and diagonal state
transitions were allowed to reduce the number of iterations.

\begin{table}[h]
    \centering
    \caption{Hill-climb for three given discrete functions}
\begin{tabular}{c|cclr|c}
    Function $f(x)$ & iterations & time $(\mu s)$ & $x^\star$ & $f(x^\star)$ & success \\
    \hline
    \texttt{grid1} & 3 & 112 & $(1,2)$ & 9 & yes \\
    \texttt{grid2} & 2 & 39 & $(3,4)$ & 32 & yes \\
    \texttt{grid3} & 8 & 115 & $(7,98)$ & -7.4 & no \\
\end{tabular}
\end{table}

\newpage

\subsection{\texttt{grid3} is problematic}

Observe in the table, in the previous section, the naive hill climbing algorithm fails
to find the global maximum of \texttt{grid3} around the point $\vect{x}^\star=(1,1)$.

\begin{figure}[h!]
    \centering
    \caption{3D plot of $f_3(\vect{x})$}
    \def\svgwidth{0.6\textwidth}
    \import{../figures/}{figure1-1.pdf_tex}
\end{figure}

\begin{figure}[h!]
    \centering
    \caption{$(-f_3(\vect{x}))^{1/8}$ to emphasize narrow global maximum band}
    \def\svgwidth{0.5\textwidth}
    \import{../figures/}{figure1-2.pdf_tex}
\end{figure}

Especially when discretized, \texttt{grid3} has a ridge on which $\vect{x}^\star=(1,1)$
lies. Hill climbing tends to get stuck along the sides this ridge, causing the
algorithm to fail to find the global maximum. Aliasing, as a result of discretization,
also results in several small isolated maxima near this ridge in the vicinity of 
$\vect{x}^\star$.

\newpage

\section{Simulated annealing}

\subsection{Our implementation}

Our implementation of simulated annealing is found in \texttt{simulated\_annealing.py}
in the function \texttt{sa\_solve()}.

\subsection{\texttt{grid1} and \texttt{grid2}}

The code which sets up and runs \texttt{sa\_solve} for \texttt{grid1} and \texttt{grid2}
is found is \texttt{sa\_grid12.py}.

\begin{table}[h]
    \centering
    \caption{Simulated annealing for \texttt{grid1} and \texttt{grid2}}
\begin{tabular}{c|cclr|c}
    Function $f(x)$ & iterations & time $(ms)$ & $x^\star$ & $f(x^\star)$ & success \\
    \hline
    \texttt{grid1} & 21 & 1 & $(1,2)$ & 9 & yes \\
    \texttt{grid2} & 351 & 5 & $(3,4)$ & 32 & yes \\
\end{tabular}
\end{table}

For both \texttt{grid1} and \texttt{grid2} our implementation of simulated annealing
finds the solution, although this technique is not ideal for these cases, which are
well suited for hill climbing. Although we could tweak the cooling schedule and other
parameters to achieve faster convergence, they are still about 1 order of magnitude
slower than hill climbing.

\emph{Note:} \texttt{sa\_solve()}'s adpative setting had to be disabled for \texttt{grid2}.

\subsection{\texttt{grid3}}

Code which calls \texttt{sa\_solve()} for \texttt{grid3} is found in \texttt{sa\_grid3.py}.

\subsubsection{Cooling schedule}


An adaptive additive exponential cooling schedule\footnote{%
    \href{http://what-when-how.com/artificial-intelligence/a-comparison-of-cooling-schedules-for-simulated-annealing-artificial-intelligence/}%
    {what-when-how.com, A Comparison of Cooling Schedules for Simulated Annealing (Artificial Intelligence)}%
}
    was used to find the global maximum 
of \texttt{grid3}. 
\begin{equation}
    T_k = T_n + (T_0 - T_n)
    \left(\frac{1}{1+e^{\frac{2\ln\left(T_0-T_n\right)}{n}
    \left(k-\frac{1}{2}n\right)}}\right)
\end{equation}

Furthermore, we multiply $T_k$ by an adaptive term $1 \leq \mu \leq 2$ which
is calculated using the distance between the value of the current state $f(s_i)$ and
$f^\star$, ie. the best value encountered so far\footnote{See footnote 1}.

\begin{equation}
    T = \mu T_k =
    \left( 1 + \frac{f(s_i)-f^\star}{f(s_i)}\right)T_k
\end{equation}

In practice, we take the \texttt{np.abs} and use \texttt{np.clip(x, 1, 2)}
to ensure that these assumptions are maintained.

The following parameters, initial temperature and number of cycles, denoted 
$T_n$ and $n$ respectivly, resulted in consistent convergence to the global maximum
near $\vect{x}^\star=(0,0)$:

$$
T_n = 10\quad\quad\text{and}\quad\quad n = 5000
$$

\subsubsection{Other cooling schedules considered}

 The following monotonic additive and multiplicative
cooling schedules were also tried, but failed to produce good results:

\begin{enumerate}
    \item Linear cooling,
    \item 
    \begin{enumerate}
        \item exponential multiplicative cooling,
        \item logarithmic multiplicative cooling,
        \item quadratic multiplicative cooling,
    \end{enumerate}
    \item
        \begin{enumerate}
            \item linear additive cooling,
            \item quadratic aditive cooling,
            \item exponential additive cooling.
        \end{enumerate}
\end{enumerate}

\subsubsection{Results}

With the above parameters, our implementation of adaptive simulated annealing 
consistently converged
very close to $\vect{x}^\star$ after $k=35754$ cycles, taking on average $1.31$ seconds.

\begin{figure}[h!]
    \caption{Simulated annealing with adaptive exponential cooling schedule}
    \centering
    \begin{subfigure}{0.5\textwidth}%
        \centering
        \subcaption{State trajectory}
        \def\svgwidth{\textwidth}
        \import{../figures/}{figure2-1.pdf_tex}
    \end{subfigure}%
    \begin{subfigure}{0.5\textwidth}%
        \centering
        \subcaption{Adaptive-AE cooling schedule}
        \def\svgwidth{\textwidth}
        \import{../figures/}{figure3-2.pdf_tex}
    \end{subfigure}%
\end{figure}

Due to the large number of steps $k$, instead of showing the whole state trajectory,
the white line denotes an exponential moving average or EMA of the trajectory with 
$\gamma=0.002$. Given the $k^{\mathrm{th}}$ state $s_k$, the EMA denoted $Y_k$ 
is calculated recursively using

\begin{equation}
    Y_k = \begin{cases}
        s_1    & \text{ for } k = 0 \\
        \gamma s_k + (1-\gamma)s_{k-1} & \text{ for } k > 1
    \end{cases}
\end{equation}

The blue cross denotes the solution found by our simulated annealing algorithm, and the
red cross denotes $\vect{x}^\star = (0,0)^T$ which is the analytical solution of
$\vect{x}^\star =
    \mathrm{argmax}\:
    f_3(\vect{x})$.     

The figure on the right shows the exponential additive cooling schedule $T_k$
being multiplied by a stochastic varrying term $1\leq \mu \leq 2$.

\subsubsection{Discussion}

In case of \texttt{grid3} our implementation of simulated annealing is able to overcome
the shortcommings of the hill climbing algorithm in \emph{section 1}. Given an appropriate
cooling schedule, the state trajectory is able to `jump' around in the isolated maxima
contained inside the narrow ridge containing $\vect{x}^\star$. This is an execellent
practical demonstration of simulated annealing's abilitiy to converge to to a global
maximum, when other methods fail and/or get stuck in local maxima.

\newpage

\section{Traveling salesman problem}

\subsection{Our implementation}

Our implementation of the \texttt{2-opt} TSP solver is found in \texttt{tsp\_solver.py}.
In addition to generating the figures below, the \texttt{dj38} problem is set up and 
solved in \texttt{dj38\_solution.py}. 

\emph{Note:} The class \texttt{DJ38Loader} will download and
parse the dataset from%
\footnote{\label{uw}%
    \href{http://www.math.uwaterloo.ca/tsp/world/djtour.html}
    {http://www.math.uwaterloo.ca/tsp/world/djtour.html}
    DJ38 - Djibouti
}, so running this code requires internet connectivity.


\subsection{Results}

\begin{figure}[h!]
    \caption{Using 2-opt to for \texttt{dj38}}
    \centering
    \begin{subfigure}{0.5\textwidth}%
        \centering
        \subcaption{Initial tour}
        \def\svgwidth{\textwidth}
        \import{../figures/}{figure4-1.pdf_tex}
    \end{subfigure}%
    \begin{subfigure}{0.5\textwidth}%
        \centering
        \subcaption{Optimum tour}
        \def\svgwidth{\textwidth}
        \import{../figures/}{figure4-2.pdf_tex}
    \end{subfigure}%
\end{figure}

Our implementation of \texttt{2-opt} finds the exact optimum tour
after 20 iterations, in 318ms. The optimum tour length was found to
be $f(\vect{t}^\star)= 6950$. Our results are identical with the results on the University
of Waterloo's website\footnote{See footnote 3.}.

\end{document}
